# 가상 면접 사례로 배우는 대규모 시스템 설계 기초  
## System Design Interview  
### 엘렉스 쉬 지음 | 이병준 옮김  
  
  
# 1장 사용자 수에 따른 규모 확장성  
수백만 사용자를 지원하는 시스템을 설계하는 것은 도전적인 과제이며,  
지속적인 계량과 끝없는 개선이 요구되는 여정이다.  
  
## 단일서버  
모든 컴포넌트가 단 한 대의 서버에서 실행되는 간단한 시스템을 설계해본다.  
  
### 사용자 요청 처리 흐름  
1. 사용자는 도메인 이름(api.mysite.com)을 이용하여 웹사이트에 접속한다.  
이 접속을 위해서는 도메인 이름을 도메인 이름 서비스(Domain Name Service, DNS)에 질의하여 IP 주소로 변환하는 과정이 필요하다.  
2. DNS 조회 결과로 IP 주소가 반환된다. 이 주소는 웹서버의 주소이다.  
3. 해당 IP 주소로 HTTP 요청이 전달된다.  
4. 요청을 받는 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.  
  
  
## 데이터베이스  
전통적인 관계형 데이터베이스와 비-관계형 데이터베이스가 있다.  
관계형 데이터베이스는 관계형 데이터베이스 관리 시스템(RDBMS)이라고도 부르는데, 가장 유명한 것은 MySQL, 오라클, PostgeSQL 등이 있다.  
관계형 데이터베이스는자료를 테이블과 열, 칼럼으로 표현한다.  
SQL을 사용하면 여러 테이블에 있는 데이터를 그 관계에 따라 조인하여 합칠 수 있다.  
  
비 관계형 데이터베이스는 NoSQL이라고도 부른다.  
NoSQL은 다시 네 부류로 나눌 수 있는데, 키-값 저장소, 그래프 저장소, 칼럼 저장소, 그리고 문서 저장소가 있다.  
일반적으로 조인 연산은 지원하지 않는다.  
  
### 비 관계형 데이터베이스의 적합한 예  
1. 아주 낮은 응답 지연시간이 요구됨  
2. 다루는 데이터가 비정형이라 관계형 데이터가 아님  
3. 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면 됨  
4. 아주 많은 양의 데이터를 저장할 필요가 있음  
  
  
## 수직적 규모 확장 vs 수평적 규모 확장  
'스케일 업'이라고도 하는 수직적 규모 확장 프로세스는 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을 추가하는 행위이다.  
반면 '스케일 아웃'이라고도 하는 수평적 규모 확장 프로세스는 더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.  
  
서버로 유입되는 트래픽의 양이 적을 때는 수직적 확장이 좋은 선택이다.  
단순한 장점이 있으나, 무한대로 증설할 수 없는 단점이 있고, 장애에 대한 자동복구 방안이나 다중화 방안을 제시하지 않는다.  
  
웹서버가 다운되거나 한계 상황에 도달하지 않게 부하 분산기 또는 로드밸런서를 도입하는 것이 최선이다.  
  
  
### 로드밸런서  
부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.  
사용자는 로드밸런서의 공개 IP주소로 접속한다.  
따라서 웹 서버는 클라이언트의 접속을 직접 처리하지 않는다.  
더 나은 보안을 위해, 서버 간 통신에는 사설 IP주소가 이용된다.  
로드밸런서는 웹 서버와 통신하기 위해 바로 이 사설 주소를 이용한다.  
  
부하 분산 집합에 또 하나의 웹 서버를 추가하고 나면, 장애를 자동복구하지 못하는 문제는 해소되며, 웹 계층의 가용성은 향상된다.  
서버 1이 다운되면 모든 트래픽은 서버 2로 전송된다. 따라서 웹 사이트 전체가 다운되는 일이 방지된다.  
웹사이트로 유입되는 트래픽이 가파르게 증가하면, 웹 서버 계층에 더 많은 서버를 추가하기만 하면 된다.  
(그러면 로드밸런서가 자동적으로 트래픽을 분산하기 시작한다.)  
  
  
### 데이터베이스 다중화  
많은 데이터베이스 관리 시스템이 다중화를 지원한다.  
보통은 서버 사이에 주-부 관계를 설정하고, 데이터 원본은 주 서버에, 사본은 부 서버에 저장하는 방식이다.  
부 데이터베이스는 읽기 연산만을 지원하고, 그 외에 DML은 주 데이터베이스로만 전달되어야 한다.  
대부분의 애플리케이션은 읽기 연산의 비중이 훨씬 높아서, 통상 부 데이터베이스의 수가 더 많다.  
  
응답 시간을 개선하기 위해서는 캐시를 붙이고, 정적 콘텐츠를 콘텐츠 전송 네트워크(CDN)으로 옮기면 개선할 수 있다.
  
  
## 캐시  
캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소이다.  
  
  
### 캐시 계층  
캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠르다.  
읽기 주도형 캐시 전략이란, 데이터가 캐시에 있으면 캐시에서 데이터를 읽고,  
없으면 데이터베이스에서 해당 데이터를 읽어 캐시에 쓰고나서 웹서버에 데이터를 반환하는 전략이다.  
  
캐시 서버를 이용하는 방법은 간단한데, 대부분의 캐시 서버들이 일반적으로 널리 쓰이는 프로그래밍 언어로 API를 제공하기 때문이다.  
  
  
### 캐시 사용시 유의할 점  
1. 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 상황에 고려해볼 만하다.  
2. 캐시는 데이터를 비활성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다.  
3. 만료 정책을 마련해 두는 것은 좋은 습관이다.  
4. 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다.  
저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우, 이 일관성은 깨질 수 있다.  
5. 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.  
6. 캐시 메모리를 과할당 하는 방법도 있다.  
7. 데이터 방출 정책에는 LRU(마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책),  
LFU(사용된 빈도가 가장 낮은 데이터를 내보내는 정책),  
FIFO(가장 먼저 캐시에 들어온 데이터를 가장 먼저 내보내는 정책)와 같은 정책 중 경우에 맞게 적용 가능하다.  
  
  
## 콘텐츠 전송 네트워크(CDN)  
CDN은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다.  
이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다.  
  
CDN과 캐시가 추가된 설계로 변화될 수 있는 부분은  
1. 정적 콘텐츠는 더 이상 웹 서버를 통해 서비스하지 않으며, CDN을 통해 제공하여 더 나은 성능을 보장한다.  
2. 캐시가 데이터베이스 부하를 줄여준다.  
  
  
## 무상태(stateless) 웹 계층  
웹 계층을 수평적으로 확장하는 방법을 고민해 볼 수 있다.  
이를 위해서는 상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거하여야 한다.  
바람직한 전략은 상태 정보를 관계형 데이터베이스나 NoSQL 같은 지속성 저장소에 보관하고,  
필요할 때 가져오도록 하는 것이다.  
이렇게 구성된 웹 계층을 무상태 웹 계층이라 부른다.  
  
  
### 무상태 아키텍처  
세션 데이터를 웹 계층에서 분리하고 지속성 데이터 보관소에 저장하도록 만들 수 있다.  
이 공유 저장소는 관계형 데이터베이스일 수도 있고, Memcached/Redis 같은 캐시 시스템일 수도 있으며,  
NoSQL일 수도 있다.  
  
  
## 데이터 센터  
두 개의 데이터 센터를 이용하는 사례를 예를 들면,  
장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내되는데, 이 절차를 지리적 라우팅이라고 부른다.  
지리적 라우팅에서의 geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP로 변환할지 결정할 수 있도록 해 주는 DNS 서비스다.  
  
시스템을 더 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여, 각기 독립적으로 확장될 수 있도록 하여야 한다.  
  
  
## 메시지 큐  
메시지 큐는 메시지의 무손실(즉, 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는, 비동기 통신을 지원하는 컴포넌트다.  
메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다.  
  
  
## 로그, 메트릭 그리고 자동화  
## 데이터베이스의 규모 확장  
## 백만 사용자, 그리고 그 이상  
시스템 규모를 확장하는 것은 지속적이고 반복적인 과정이다.  
예를 들어, 시스템을 최적화하고 더 작은 단위의 서비스로 분할해야 할 수도 있다.  
  
시스템 규모 확장을 위해 살펴본 기법  
1. 웹 계층은 무상태 계층으로  
2. 모든 계층에 다중화 도입  
3. 가능한 한 많은 데이터를 캐시할 것  
4. 여러 데이터 센터를 지원할 것  
5. 정적 콘텐츠는 CDN을 통해 서비스할 것  
6. 데이터 계층은 샤딩을 통해 그 규모를 확장할 것  
7. 각 계층은 독립적 서비스로 분할할 것  
8. 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것  
  
  
  
# 2장 개략적인 규모 추정  
## 2의 제곱수  
최소 단위는 1바이트이고, 8비트이다.  
ASCII 문자 하나가 차지하는 메모리 크기가 1바이트이다.  
  
  
## 모든 프로그래머가 알아야 하는 응답지연 값  
수치들을 분석하면 다음과 같은 결론이 나온다.  
1. 메모리는 빠르지만 디스크는 아직도 느리다.  
2. 디스크 탐색(seek)은 가능한 한 피하라.  
3. 단순한 압축 알고리즘은 빠르다.  
4. 데이터를 인터넷으로 전송하기 전에 가능하면 압축하라.  
5. 데이터 센터는 보통 여러 지역(region)에 분산되어 있고, 센터들 간에 데이터를 주고받는 데는 시간이 걸린다.  
  
  
## 가용성에 관계된 수치들  
고가용성은 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력을 지칭하는 용어다.  
고가용성을 표현하는 값은 퍼센트로 표현하는데, 100%는 시스템이 단 한 번도 중단된 적이 없었음을 의미한다.  
대부분의 서비스는 99%에서 100% 사이의 값을 갖는다.  
  
  
## 예제: 트위터 QPS와 저장소 요구량 추정  
## 팁  
개략적인 규모 추정과 관계된 면접에서 가장 중요한 것은 문제를 풀어 나가는 절차다.  
근사치를 활용한 계산을 하고, 가정들은 적어 두고, 단위를 붙이며,  
QPS, 캐시 요구량, 서버 수 등을 추정하는 계산 연습을 해 두자.  
  
  
  
# 3장 시스템 설계 면접 공략법  
시스템 설계 면접은 두 명의 동료가 모호한 문제를 풀기 위해 협력하여 그 해결책을 찾아내는 과정에 대한 시뮬레이션이다.  
이 면접은 설계 기술을 시연하는 자리이고, 설계 과정에서 내린 결정들에 대한 방어 능력을 보이는 자리이며,  
면접관의 피드백을 건설적인 방식으로 처리할 자질이 있음을 보이는 자리이다.  
  
  
## 효과적 면접을 위한 4단계 접근법  
### 1단계 문제 이해 및 설계 범위 확정  
바로 답부터 들이밀지 말고, 속도를 늦춰 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 한다.  
  
  
### 2단계 개략적인 설계안 제시 및 동의 구하기  
개략적인 설계안을 제시하고 면접관의 동의를 얻는다. 이 과정은 면접관과 협력하여 진행하면 좋다.  
화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그리고,  
제약사항들을 만족하는지 개략적으로 계산해본다.  
  
  
### 3단계 상세 설계  
설계 대상 컴포넌트 사이의 우선순위를 정한다.  
  
  
### 4단계 마무리  
면접관은 후속 질문을 던질수도 있고, 스슬 추가 논의를 진행하도록 할 수도 있다.  
1. 시스템 병목구간, 혹은 좀 더 개선 가능한 지점을 찾아내라 주문할 수 있다.  
2. 만든 설계를 한번 다시 요약해주는 것도 도움이 될 수 있다.  
3. 오류가 발생하면 무슨 일이 생기는지 짚어본다.  
4. 운영 이슈도 논할 가치가 충분하다.(메트릭은 어떻게 수집하고 모니터링 할 것인가? 로그는? 시스템은 어떻게 배포해 나갈 것인가?)  
5. 규모 확장 요구에 어떻게 대처할 것인가  
6. 다루지 못했던 세부적 개선사항들  
  
  
### 시간 배분  
1단계 - 문제 이해 및 설계 범위 확정: 3분에서 10분  
2단계 - 개략적 설계안 제시 및 동의 구하기: 10분에서 15분  
3단계 - 상세 설명: 10분에서 25분  
4단계 - 마무리: 3분에서 5분  
  
  
  
# 4장 처리율 제한 장치의 설계  
네트워크 시스템에서 처리율 제한 장치(rate limiter)는 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)를 제어하기 위한 장치다.  
HTTP를 예를 들면 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.  
  
### API에 처리율 제한 장치를 두면 좋은 점  
1. DOS(Denial of Service) 공격에 의한 자원 고갈을 방지할 수 있다.  
(DOS는 한 대의 PC만으로도 수행할 수 있지만, DDOS는 분산된 여러 PC를 동시에 이용하여 서버의 가동을 방해하는 측면에서 차이가 있다.)  
2. 서버를 많이 두지 않아도 되기 때문에 비용을 절감한다.  
3. 서버 과부하를 막는다.  
  
  
## 1단계 문제 이해 및 설계 범위 확정  
### 요구사항  
1. 설정된 처리율을 초과하는 요청은 정확하게 제한한다.  
2. 낮은 응답시간: 이 처리울 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어서는 곤란한다.  
3. 가능한 한 적은 메모리를 써야 한다.  
4. 분산형 처리율 제한: 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.  
5. 예외 처리: 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.  
6. 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다.  
  
  
  
## 2단계 개략적 설계안 제시 및 동의 구하기  
기본적으로는 클라이언트-서버 통신 모델을 사용.  
  
### 처리율 제한 장치는 어디에 둘 것인가?  
클라이언트 측에 두는 것 보다는, 서버 측에 두거나 처리율 제한 미들웨어를 만들어 통제한다.  
폭 넓게 채택된 기술인 클라우드 마이크로서비스의 경우, 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다.  
(API 게이트웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용목록 관리 등을 지원하는 완전 위탁관리형 서비스로,  
즉 클라우드 업체가 유지 보수를 담당하는 서비스이다.)  
  
  
### 처리율 제한 알고리즘  
1. 토큰 버킷  
2. 누출 버킷  
3. 고정 윈도 카운터  
4. 이동 윈도 로그  
5. 이동 윈도 카운터  
  
  
### 1. 토큰 버킷 알고리즘  
#### 동작원리  
토큰 버킷은 지정된 용량을 갖는 컨테이너이다.  
이 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워진다.  
토큰이 꽉 찬 버킷에는 더 이상의 토큰은 추가되지 않는다.  
  
이 토큰 버킷 알고리즘은 2개 인자를 받는다.  
1. 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수  
(통상적으로, API 엔드포인트마다 별도의 버킷을 둔다.)  
2. 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는가  
  
  
#### 장점  
1. 구현이 쉽다.  
2. 메모리 사용 측면에서도 효율적이다.  
3. 짧은 시간에 집중되는 트래픽도 처리 가능하다.  
(버킷에 남은 토큰이 있기만 하면 요청은 시스템에 전달된다.)  
  
#### 단점  
1. 이 알고리즘은 버킷 크기와 토큰 공급률이라는 두 개 인자를 가지고 있는데,  
이 값을 적절하게 튜닝하는 것은 까다로운 일이 될 것이다.  
  
  
### 2. 누출 버킷 알고리즘  
#### 동작원리  
토큰 버킷 알고리즘과 비슷하지만, 처리율이 고정되어 있다.(고정 속도로 처리)  
보통 FIFO 큐로 구현하여, 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.  
  
#### 2개의 인자를 사용  
1. 버킷 크기: 큐 사이즈와 같은 값으로, 큐에는 처리될 항목들이 보관된다.  
2. 처리율: 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값이다. 보통 초 단위로 표현한다.  
  
  
#### 장점  
1. 큐의 크기가 제한되어 있어, 메모리 사용량 측면에서 효율적이다.  
2. 고정된 처리율을 갖고 있기 때문에, 안정적 출력이 필요한 경우에 적합하다.  
  
#### 단점  
1. 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고,  
그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다.  
2. 두 개 인자를 올바르게 튜닝하기가 까다로울 수 있다.  
  
  
### 3. 고정 윈도 카운터 알고리즘  
#### 동작 원리  
1. 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.  
2. 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.  
3. 이 카운터의 값이 사전에 설정된 임계치에 도달하면, 새로운 요청은 새 윈도가 열릴 때까지 버려진다.  
  
#### 이슈  
윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도에 할당된 양보다 더 많은 요청이(허용 한도의 2배까지) 처리 될 수 있다.  
  
  
#### 장점  
1. 메모리 효율이 좋다.  
2. 이해하기 쉽다.  
3. 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.  
  
#### 단점  
1. 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.  
  
  
### 4. 이동 윈도 로깅 알고리즘  
#### 동작 원리  
고정 윈도 카운터 알고리즘의 단점을 해결한다.  
1. 요청의 타임스탬프를 추적한다.  
타임스탬프 데이터는 보통 레디스의 정렬 집합 같은 캐시에 보관한다.  
2. 새 요청이 오면 타임스탬프는 제거한다. 만료된 타임스탬프는 그 값이 현재 윈도의 시작 시점보다 오래된 타임스탬프를 말한다.  
3. 새 요청의 타임스탬프를 로그에 추가한다.  
(보통 로그에 보관되는 값은 리눅스 타임스탬프이다.)  
4. 로그의 크기가 허용치보다 같거나 작으면, 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.  
  
  
#### 장점  
1. 이 알고리즘이 구현하는 처리율 제한 메커니즘은 아주 정교하다.  
(어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.)  
  
#### 단점  
1. 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다.  
  
  
### 5. 이동 윈도 카운터 알고리즘  
고정윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것이다.  

#### 접근법1  
처리율 제한 장치의 한도가 분당 7개의 요청으로 설정되어 있을 때,  
이전 1분동안 5개의 요청이, 그리고 현재 1분동안 3개의 요청이 왔고,  
새 요청이 도착하면  현재 윈도에 몇 개의 요청이 온 것으로 보고 처리해야 하는가?  
-> 현재 1분간의 요청 수(3) + 직전 1분간의 요청수(5) * 이동 윈도와 직전 1분이 겹치는 비율(70%) = 6.5개(반올림 혹은 내림하여 적용)  
  
  
#### 장점  
1. 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.  
2. 메모리 효율이 좋다.  
  
#### 단점  
1. 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.  
  
  
### 개략적인 아키텍처  
카운터를 보관하는 곳은 메모리상에서 동작하는 캐시가 바람직한데, 빠른데다 시간에 기반한 만료 정책을 지원한다.  
일례로 레디스는 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 저장 장치로서, INCFR과 EXPIRE의 두 가지 명령어를 지원한다.  
1. INCR: 메모리에 저장된 카운터의 값을 1만큼 증가시킨다.  
2. EXPIRE: 카운터에 타임아웃 값을 설정한다. 설정된 시간이 지나면 카운터는 자동으로 삭제된다.  
  
  
  
## 3단계 상세 설계  
### 처리율 제한 규칙  
리프트는 처리율 제한에 오픈 소스를 사용하고 있다.  
   
### 처리율 한도 초과 트래픽의 처리  
클라이언트는 자기 요청이 처리율 제한에 걸리는지를 HTTP 응답 헤더를 통해 알 수 있다.  
다음의 HTTP 헤더를 클라이언트에게 보낸다.  
1. X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수.  
2. X-RateLimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수.  
3. X-RateLimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림.  
(사용자가 너무 많은 요청을 보내면 429 too many requests 오류를 X-Ratelimit-Retry-After 헤더와 함께 반환하도록 한다.)  
  
  
### 상세 설계  
1. 처리율 제한 규칙은 디스크에 보관한다. 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장한다.  
2. 클라이언트가 요청을 서버에 보내면 요청은 먼저 처리율 제한 미들웨어데 도달한다.  
3. 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다.  
아울러 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다.  
가져온 값들에 근거하여 해당 미들웨어는 결정을 내린다.  
  
3-1. 해당 요청이 처리율 제한에 걸리지 않은 경우에는 API 서버로 보낸다.  
3-2. 해당 요청이 처리율 제한에 걸렸다면 429 too many requests 에러를 클라이언트에 보낸다.  
(해당 요청은 그대로 버릴 수도 있고 메시지 큐에 보관할 수도 있다.)  
  
  
### 분산 환경에서의 처리율 제한 장치의 구현  
두가지 어려운 문제가 있다.  
1. 경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락이다.  
하지만 락은 시스템의 성능을 상당히 떨어뜨린다는 문제가 있다.  
해결책은 루아 스크립트 혹은 정렬 집합이라 불리는 레디스 자료구조를 쓰는 것이다.  
  
2. 동기화 이슈는 고정 세션을 활용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하여 해결할 수 있다.  
규모면에서 확장 가능하지 않고 유연하지도 않기 때문에,  
레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이 더 나은 해결책이다.  
  
  
  
# 5장 안정 해시 설계  
수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요하다.  
안정 해시는 이 목표를 달성하기 위해 보편적으로 사용하는 기술이다.  
  
  
## 해시 키 재배치(rehash) 문제  
N개의 캐시 서버가 있을 때, 이 서버들에 부하를 균등하게 나누는 보편적 방법은 아래의 해시 함수를 사용하는 것이다.  
serverIndex = hash(key) % N  
1번 서버에 장애가 발생한다면, 보관되어 있는 키 뿐만 아닌 대부분의 키가 재분배 된다.  
#### 이해 안되는 문장 : (p.79)1번 서버가 죽으면 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속하게 된다는 뜻이다.  
안정 해시는 이 문제를 효과적으로 해결하는 기술이다.  
  
  
## 안정 해시  
안정 해시는 해시 테이블 크기가 조정될 때 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술이다.  
여기서 k는 키의 개수이고, n은 슬롯의 개수다.  
이와는 달리 대부분의 전통적 해시 테이블은 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다.  
  
  
### 기본 구현법의 두 가지 문제  
안정 해시 알고리즘의 기본 절차는 다음과 같다.  
1. 서버와 키를 균등 분포 해시 함수를 사용해 해시 링에 배치한다.  
2. 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버다.  

첫번째 문제는 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는 게 불가능하다.  
(파티션은 인접한 서버 사이의 해시 공간이다.)  
어떤 서버는 굉장히 큰 해시 공간을 할당 받는 상황이 가능해진다.  
  
두번째 문제는 키의 균등 분포를 달성하기가 어렵다.  
  
이 문제를 해결하기 위해 제안된 기법이 가상 노드 또는 복제라 불리는 기법이다.  
  
  
## 마치며  
안정 해시의 이점은 다음과 같다.  
1. 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.  
2. 데이터가 보다 균등하게 분포하게 되므로, 수평적 규모 확장성을 달성하기 쉽다.  
3. 핫스팟 키 문제를 줄인다.(특정 샤드에 대한 접근이 지나치게 빈번하면 서버 과부하 문제가 생길 수 있다.)  
  
### 널리 쓰이는 유명한 예  
1. 디스코드 채팅 어플리케이션  
  
  
  
# 6장 키-값 저장소 설계  
키-값 저장소는 키-값 데이터베이스라고도 불리는 비 관계형 데이터베이스이다.  
성능상의 이유로, 키는 짧을수록 좋다.  
키-값 저장소로 널리 알려진 것으로는 ``아마존 다이나모, memcached, 레디스`` 같은 것들이 있다.  
  
## 문제 이해 및 설계 범위 확정  
이번 장에서는 다음 특성을 갖는 키-값 저장소를 설계해 볼 것이다.  
1. 키-값 쌍의 크기는 10KB 이하이다.  
2. 큰 데이터를 저장할 수 있어야 한다.  
3. 높은 가용성을 제공해야 한다. 따라서 시스템은 장애가 있더라도 빨리 응답해야 한다.  
4. 높은 규모 확장성을 제공해야 한다. 따라서 트래픽 양에 따라 자동적으로 서버 증설/삭제가 이루어져야 한다.  
5. 데이터 일관성 수준은 조정이 가능해야 한다.  
6. 응답 지연시간(latency)이 짧아야 한다.  
  
  
## 단일 서버 키-값 저장소  
한 대 서버만 사용하여 키-값 저장소를 설계하는 가장 직관적인 방법은, 키-값 쌍 전부를 메모리에 해시 테이블로 저장하는 것이다.  
이 접근법은 빠른 속도를 보장하긴 하지만, 모든 데이터를 메모리 안에 두는 것이 불가능할 수 있다는 약점을 갖고 있다.  
개선책으로는 ``데이터 압축``과 ``자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장``할 수 있다.  
그러나 많은 데이터를 저장하려면, ``분산 키-값 저장소``를 만들 필요가 있다.  
  
  
## 분산 키-값 저장소  
분산 키-값 저장소는 ``분산 해시 테이블``이라고도 불리는데, 키-값 쌍을 여러 서버에 분산시킨다.  
  
### CAP 정리  
CAP 정리는 데이터 일관성(consistency), 가용성(availability), 파티션 감내(partition tolerance)라는  
세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것이 불가능하다는 정리이다.  
  
- 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속했느냐에 관계없이 언제나 같은 데이터를 보게 되어야 한다.  
- 가용성: 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도, 항상 응답을 받을 수 있어야 한다.  
- 파티션 감내: 파티션 감내는 네트워크에 파티션이 생기더라도 시스템은 계속 동작하여야 한다.  
(파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다.)  
  
CAP 정리는 이들 가운데 어떤 두 가지를 충족하려면, 나머지 하나는 반드시 희생되어야 한다는 것을 의미한다.  
(CA 시스템의 경우, 분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계해야 해서, 실세계에서는 존재하지 않는다.)  
  
  
### 시스템 컴포넌트  
키-값 저장소 구현에 사용될 핵심 컴포넌트들 및 기술들을 살펴본다.  
  
### 1. 데이터 파티션  
데이터를 작은 파티션들로 분할한 다음, 여러 대 서버에 저장한다.  
데이터를 파티션 단위로 나눌 때는 두가지 문제를 중요하게 따져봐야 한다.  
- 데이터를 여러 서버에 고르게 분산할 수 있는가  
- 노드가 추가되거나 삭제될 때, 데이터의 이동을 최소화할 수 있는가  
  
안정 해시는 이런 문제를 푸는 데 적합한 기술이다.  
안정 해시를 사용하여 데이터를 파티션 하면, ``규모 확장 자동화`` 및 ``다양성(각 서버의 용량에 맞게 가상 노드의 수를 조정)``의 이점이 있다.  
  
  
### 2. 데이터 다중화  
데이터를 N개 서버에 비동기적으로 다중화할 필요가 있다.  
여기서 N은 튜닝 가능한 값이며, 가상 노드를 사용한다면 N개의 노드가 대응될 실제 물리 서버의 개수가 N보다 작아질 수 있다.  
이 문제를 피하려면, 노드를 선택할 때 같은 물리 서버를 중복 선택하지 않도록 해야한다.  
  
같은 데이터 센터에 속한 노드는 정전, 네트워크 이슈, 자연재해 등의 문제를 동시에 겪을 가능성이 있다.  
따라서 안정성을 담보하기 위해 데이터의 사본은 다른 센터의 서버에 보관하고, 센터들은 고속 네트워크로 연결한다.  
  
  
### 3. 데이터 일관성  
여러 노드에 다중회된 데이터는 적절히 동기화가 되어야 한다.  
``정족수 합의(Quorum Consensus)`` 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있다.  
- N = 사본 개수  
- W = 쓰기 연산에 대한 정족수.  
(쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 한다.)  
- R = 읽기 연산에 대한 정족수.  
  
가능한 몇가지 구성  
- R = 1, W = N: 빠른 읽기 연산에 최적화된 시스템  
- W = 1, R = N: 빠른 쓰기 연산에 최적화된 시스템  
- W + R > N: 강한 일관성이 보장됨(보통 N = 3, W = R = 2)  
(일관성을 보증할 최신 데이터를 가진 노드가 최소 하나는 겹칠 것이다.)  
- W + R <= N: 강한 일관성이 보장되지 않음  
  
  
### 4. 일관성 불일치 해소  
#### 일관성 모델  
- 강한 일관성: 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다.  
- 약한 일관성: 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.  
- 최종 일관성: 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영되는 모델.  
  
  
#### 비 일관성 해소 기법: 데이터 버저닝  
버저닝은 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것을 의미한다.  
따라서 각 버전의 데이터는 변경 불가능하다.  
  
쓰기에 대한 두 연산이 동시에 이뤄지는 충돌을 발견하고 자동으로 해결해 낼 버저닝 시스템이 필요한데,  
``벡터 시계``는 이런 문제를 푸는데 보편적으로 사용되는 기술이다.  
벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 매단 것이다.  
  
두가지 단점이 있는데, 첫 번째는 충동 감지 및 해소 로직이 클라이언트에 들어가야 하므로, 클라이언트 구현이 복잡해진다.  
두번째는 [서버: 버전]의 순서쌍 개수가 굉장히 빨리 늘어난다.  
  
그러나 대부분의 기업에서 벡터 시계는 적용해도 괜찮은 솔루션일 것이다.  
  
  
### 5. 장애 처리  
#### 장애 감지  
분산 시스템에서는 그저 한 대 서버가 "지금 서버 A가 죽었습니다"라고 한다해서 바로 서버 A를 장애처리 하지는 않는다.  
보통 두 대 이상의 서버가 똑같이 서버 A의 장애를 보고해야 해당 서버에 실제로 장애가 발생했다고 간주하게 된다.  
  
모든 노드 사이에 멀티캐스팅 채널을 구축하는 것이 서버 장애를 감지하는 가장 손쉬운 방법이나, 서버가 많을 때는 비효율적이다.  
``가십 프로토콜`` 같은 분산형 장애 감지 솔루션을 채택하는 편이 효율적이다.  
1. 각 노드는 멤버십 목록을 유지한다. 멤버십 목록은 각 멤버 ID와 그 박동 카운터 쌍의 목록이다.  
2. 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.  
3. 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.  
4. 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.  
5. 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면, 해당 멤버는 장애 상태인 것으로 간주한다.  
  
  
#### 일시적 장애 처리  
엄격한 정족수 접근법을 쓴다면, 읽기와 쓰기 연산을 금지한다.  
느슨한 정족수 접근법은 쓰기, 연산을 수행할 W개의 건강한 서버와, 읽기 연산을 수행할 R개의 건강한 서버를 해시 링에서 고른다.  
  
#### 영구적 장애 처리  
``반-엔트로피`` 프로토콜을 구현하여 사본들을 동기화한다.  
(반-엔트로피 프로토콜은 사본들을 비교하여 최신 버전으로 갱신하는 과정을 포함한다.)  
  
사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해서는 ``머클 트리``를 사용한다.  
(해시 트리라고도 불리는 머클 트리는 각 노드에 그 자식 노드들에 보관된 값의 해시, 또는 자식 노드들의 레이블로부터 계산된 해시값을 레이블로 붙여두는 트리이다.)  
해시 트리를 사용하면 대규모 자료 구조의 내용을 효과적이면서도 안전한 방법으로 검증할 수 있다.  
  
#### 데이터 센터 장애 처리  
데이터 센터 장애에 대응할 수 있는 시스템을 만들려면 데이터를 여러 데이터 센터에 다중화하는 것이 중요하다.  
  
  
### 6. 시스템 아키텍처 다이어그램  
아키텍처의 주된 기능은 다음과 같다.  
- 클라이언트는 키-값 저장소가 제공하는 두 가지 단순한 API와 통신한다.(get, put)  
- 중재자는 클라이언트에게 키-값 저장소에 대한 프락시 역할을 하는 노드다.  
- 노드는 안정 해시의 해시 링 위에 분포한다.  
- 노드를 자동으로 추가 또는 삭제할 수 있도록, 시스템은 완전히 분산된다.  
- 데이터는 여러 노드에 다중화된다.  
- 모든 노드가 같은 책임을 지므로, SPOF(Single Point of Failure)는 존재하지 않는다.  
  
  
### 7. 쓰기 경로  
쓰기 요청이 트정 노드에 전달되면,
- 쓰기 요청이 커밋 로그 파일에 기록된다.  
- 데이터가 메모리 캐시에 기록된다.  
- 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable(Sorted-String Table)에 기록된다.  
  
  
### 8. 읽기 경로  
읽기 요청을 받은 노드는 데이터가 메모리 캐시에 있는지부터 살핀다.  
있는 경우에는 해당 데이터를 클라이언트에게 반환한다.  
  
메모리에 없는 경우에는 디스크에서 가져와야 하는데, 어느 SSTable에 찾는 키가 있는지 알아낼 효율적인 방법이 필요하다.  
이런 문제를 푸는데는 ``블룸 필터``가 흔히 사용된다.  
  
  
## 요약  
분산 키-값 저장소가 가져야 하는 기능과, 그 기능 구현에 이용되는 기술  
1. 대규모 데이터 저장: 안정 해시를 이용해 서버들에 부하 분산  
2. 읽기 연산에 대한 높은 가용성 보장: 데이터를 여러 데이터센터에 다중화  
3. 쓰기 연산에 대한 높은 가용성 보장: 버저닝 및 벡터 시계를 사용한 충돌 해소  
4. 데이터 파티션: 안정 해시  
5. 점진적 규모 확장성: 안정 해시  
6. 다양성: 안정 해시  
7. 조정 가능한 데이터 일관성: 정족수 합의  
8. 일시적 장애 처리: 느슨한 정족수 프로토콜과 단서 후 임시 위탁  
9. 영구적 장애 처리: 머클 트리  
10. 데이터 센터 장애 대응: 여러 데이터 센터에 걸친 데이터 다중화    
  
  
  
# 7장 분산 시스템을 위한 유일 ID 생성기 설계  
auto_increment 속성이 설정된 관계형 데이터베이스의 기본 키를 쓰는 경우, 분산 환경에서 이 접근법은 통하지 않는다.  
데이터베이스 서버 한 대로는 그 요구를 감당할 수 없을뿐더러, 여러 데이터베이스 서버를 쓰는 경우에는 지연시간(delay)을 낮추기가 무적 힘들다.  
   
## 1단계 문제 이해 및 설계 범위 확정  
요구사항 정리  
1. ID는 유일해야 한다.  
2. ID는 숫자로만 구성되어야 한다.  
3. ID는 64비트로 표현될 수 있는 값이어야 한다.  
4. ID는 발급 날짜에 따라 정렬 가능해야 한다.  
5. 초당 10,000개의 ID를 만들 수 있어야 한다.  
  
  
## 2단계 개략적 설계안 제시 및 동의 구하기  
분산 시스템에서 유일성이 보장되는 ID를 만드는 방법은 여러 가지다.  
### 1. 다중 마스터 복제  
이 접근법은 데이터베이스의 auto_increment 기능을 k만큼(현재 사용 중인 데이터베이스 서버의 수) 증가시키게 활용하는 것이다.  
데이터베이스 수를 늘리면 초당 생산 가능 ID 수도 늘릴 수 있다.  
  
단점  
- 여러 데이터 센터에 걸쳐 규모를 늘리기 어렵다.  
- ID의 유일성은 보장되겠지만, 그 값이 시간 흐름에 맞추어 커지도록 보장할 수는 없다.  
- 서버를 추가하거나 삭제할 때도 잘 동작하도록 만들기 어렵다.  
(단점 세가지 다 와닿지 않는다..)  
  
  
### 2. UUID(Universally Unique Identifier)  
UUID는 컴퓨터 시스템에 저장되는 정보를 유일하게 식별하기 위한 128비트짜리 수다.  
  
장점  
- UUID를 만드는 것은 단순하다. 서버 사이의 조율이 필요 없으므로 동기화 이슈도 없다.  
- 각 서버가 자기가 쓸 ID를 알아서 만드는 구조이므로 규모 확장도 쉽다.  
  
단점  
- ID가 128비트로 길다.  
- ID를 시간순으로 정렬할 수 없다.  
- ID에 숫자 아닌 값이 포함될 수 있다.  
  
   
### 3. 티켓 서버  
auto_increment 기능을 갖춘 데이터베이스 서버, 즉 티켓 서버를 중앙 집중형으로 하나만 사용하는 것이다.  
  
장점  
- 유일성이 보장되는 오직 숫자로만 구성된 ID를 쉽게 만들 수 있다.  
- 구현하기 쉽고, 중소 규모 애플리케이션에 적합하다.  
  
단점  
- 티켓 서버가 장애가 발생하면, 해당 서버를 이용하는 보든 시스템이 영향을 받는다.  
(티켓 서버를 여러 대 준비하면, 동기화 같은 새로운 문제가 발생한다.)  
  
  
### 4. 트위터 스노플레이크 접근법  
ID를 바로 생성하는 대신, ``각개 격파 전략(divide and conquer)``을 적용해서,  
생성해야 하는 ID의 구조를 여러 절(section)으로 분할한다.  
- 사인 비트: 1비트를 할당하여, 음수와 양수를 구별하는데 사용한다.  
- 타임스탬프: 41비트를 할당하여, 기원 시각 이후로 몇 밀리초가 경과했는지를 나타낸다.  
- 데이터센터 ID: 5비트를 할당하여, 32개의 데이터센터를 지원할 수 있다.  
- 서버 ID: 5비트를 할당하여, 데이터센터당 32개의 서버를 사용할 수 있다.  
- 일련번호: 12비트를 할당하여 각 서버에서는 ID를 생성할 때마다 이 일련번호를 1만큼 증가시킨다.  
(이 값은 1밀리초가 경과할 때마다 0으로 초기화된다?)  
  
  
    
## 3단계 상세 설계  
트위터 스노플레이크 접근법에서 데이터센터 ID와 서버 ID는 시스템이 시작할 때 결정된다.  
일반적으로 시스템 운영 중에는 바뀌지 않으며, 잘못 변경하게 되면 ID 충돌이 발생할 수 있다.  
타임스탬프나 일련번호는 ID 생성기가 돌고 있는 중에 만들어지는 값이다.  
  
### 타임스탬프  
타임스탬프는 시간이 흐름에 따라 점점 큰 값을 갖게 되므로, 결국 ID는 시간순으로 정렬 가능하게 될 것이다.  
41비트로 표현할 수 있는 최댓값은 대략 69년에 해당한다.  
69년이 지나면 기원 시각을 바꾸거나, ID 체계를 다른 것으로 ``이전(migration)``하여야 한다.  
  
### 일련번호  
일련번호는 12비트이므로, 2^12개의 값을 가질 수 있다.  
어떤 서버가 같은 밀리초 동안 하나 이상의 ID를 만들어 낸 경우에만 0보다 큰 값을 갖게 된다.  
  
  
## 4단계 마무리  
설계를 진행하고 시간이 조금 남았다면, 면접관과 다음을 추가로 논의할 수 있다.  
1. 시계 동기화  
이번 설계를 진행하면서 ID 생성 서버들이 전부 같은 시계를 사용한다고 가정했다.  
하지만 이런 가정은 하나의 서버가 여러 코어에서 실행될 경우 유효하지 않을 수 있다.  
또한 여러 서버가 물리적으로 독립된 여러 장비에서 실행되는 경우에도 유효하지 않을 수 있다.  
NTP(Network Time Protocol)은 이 문제를 해결하는 가장 보편적 수단이다.  
  
2. 각 절(section)의 길이 최적화  
동시성이 낮고 수명이 긴 애플리케이션이라면, 일련번호 절의 길이를 줄이고, 타임스탬프 절의 길이를 늘리는 것이 효과적일 수도 있다.  
  
3. 고가용성(high availability)  
ID 생성기는 필수 불가결 컴포넌트이므로, 아주 높은 가용성을 제공해야 할 것이다.  
  
  
  
# 8장 URL 단축키 설계   
이번 장에서는 고전적인 시스템  설계 문제 가운데 하나인, ``tiny url`` 같은 URL 단축기를 설계하는 문제를 풀어본다.  
  
## 1단계 문제 이해 및 설계 범위 확정  
개략적 추정  
1. 쓰기 연산: 매일 1억 개의 단축 URL 생성  
2. 초당 쓰기 연산: 1억/24/3,600 = 1,160  
3. 읽기 연산: 읽기 연산과 쓰기 연산 비율은 10:1이라고 가정(읽기 연산: 1,160x10 = 11,600)  
4. 10년간 운영할 경우 1억x365x10 = 3,650억 개의 레코드를 보관해야 한다.  
5. 축약 전 URL의 평균 길이는 100이라 가정  
6. 10년 동안 필요한 저장 용량은 3,650억x100바이트 = 36.5TB  
  
  
## 2단계 개략적 설계안 제시 및 동의 구하기  
### API 엔드포인트  
URL 단축기는 기본적으로 두 개의 엔드포인트를 필요로 한다.  
1. URL 단축용 엔드포인트: 새 단축 URL을 생성하고자 하는 클라이언트는 이 엔드 포인트에 단축할 URL을 인자로 실어서 POST 요청을 해야 한다.  
```  
POST /api/vi/data/shorten  
인자: {longUrl: longURLstring }  
반환: 단축 URL  
```  
(단축  URL이 반환이 맞는가..?)  
  
2. URL 리디렉션용 엔드포인트: 단축 URL에 대해서 HTTP 요청이 오면 원래 URL로 보내주기 위한 용도의 엔드포인트  
```  
GET /api/vi/shortURL  
반환: HTTP 리디렉션 목적지가 될 원래 URL  
```  
  
  
### URL 리디렉션  
브라우저에 단축 URL을 입력하면, 단축 URL을 받은 서버는 그 URL을 원래 URL로 바꾸어서 301 응답의 Location 헤더에 넣어 반환한다.  
301 응답과 302 응답에 차이가 있는데, 둘 다 리디렉션 응답이긴 하지만 차이가 있다.  
  
1. 301 Permanently Moved: 해당 URL에 대한 HTTP 요청의 처리 책임이 영구적으로 Location 헤더에 반환된 URL로 이전되었다는 응답.  
브라우저는 이 응답을 캐시한다.  
첫번째 요청만 단축 URL 서버로 전송될 것이기 때문에, 서버 부하를 줄이는 것이 중요할때 사용하는 것이 좋다.  
  
2. 302 Found: 주어진 URL로의 요청이 일시적으로 Location 헤더가 지정하는 URL에 의해 처리되어야 한다는 응답.  
따라서 클라이언트의 요청은 언제나 단축 URL 서버에 먼저 보내진 후에, 원래 URL로 리디렉션 되어야 한다.  
트래픽 분석이 중요할 때, 클릭 발생률이나 발생 위치를 추적하는 데 좀 더 유리하다.  
  
URL 리디렉션을 구현하는 가장 직관적인 방법은 해시 테이블을 사용하는 것이다.  
```  
- 원래 URL = hashTable.get(단축 URL)  
- 301 또는 302 응답 Location 헤더에 원래 URL을 넣은 후 전송  
```  
  
  
### URL 단축  
단축 URL이 ``www.tinyurl.com/{hashValue}``과 같은 형태라면, 이 해시 함수는 다음 요구사항을 만족해야 한다.  
1. 입력으로 주어지는 긴 URL이 다른 값이면 해시 값도 달라야 한다.  
2. 계산된 해시 값은 원래 입력으로 주어졌던 긴 URL로 복원될 수 있어야 한다.  
  
  
## 3단계 상세 설계  
### 데이터 모델  
나은 방법은 ``<단축 URL, 원래 URL>`` 의 순서쌍을 관계형 데이터베이스에 저장하는 것이다.  
  
### 해시 함수  
해시 함수는 원래 URL을 단축 URL로 변환하는 데 쓰인다.  
편의상 해시 함수가 계산하는 단축 URL 값을 ``hashValue``라고 지칭한다.  
  
### 해시 값 길이  
hashValue는 숫자와 문자들로 구성되서, 사용될 수 있는 문자의 개수는 62개다.  
해시 함수 구현에 쓰일 기술로는 ``해시 후 충동 해소`` 방법이 있고, ``base-62 변환``법이 있다.  
  
### 해시 후 충돌 해소  
긴 URL을 줄이려면, 원래 URL을 7글자 문자열로 줄이는 해시 함수가 필요하다.  
손쉬운 방법은 ``CRC32, MD5, SHA-1``같이 잘 알려진 해시 함수를 이용하는 것이다.  
7글자 보다 길다면, 충돌이 해소될 때까지 사전에 정한 문자열을 해시값에 덧붙인다.  
  
단점  
한번 이상 데이터베이스 질의를 해야 하므로 오버헤드가 크다.  
  
개선  
블룸 필터를 사용한다.  
  
  
### base-62 변환  
수의 표현 방식이 다른 두 시스템이 같은 수를 공유하여야 하는 경우에 유용하다.  
  
### 두 접근법 비교  
1. 해시 후 충돌 해소 전략  
- 단축 URL 길이가 고정됨  
- 유일성이 보장되는 ID 생성기가 필요치 않음  
- 충돌이 가능해서 해소 전략이 필요  
- ID로부터 단축 URL을 계산하는 방식이 아니라서, 다음에 쓸 수 있는 URL을 알아내는 것이 불가능  
  
2. base-62 변환  
- 단축 URL의 길이가 가변적이고, ID 값이 커지면 같이 길어짐.  
- 유일성 보장 ID 생성기가 필요  
- ID의 유일성이 보장된 후에야 적용 가능한 전략이라 충돌은 아예 불가능  
- ID가 1씩 증가하는 값이라고 가정하면, 다음에 쓸 수 있는 단축 URL이 무엇인지 쉽게 알아낼 수 있어서 보안상 문제가 될 소지가 있음.  
  
  
### URL 단축기 상세 설계  
처리 흐름  
1. 입력으로 긴 URL을 받는다.  
2. 데이터베이스에 해당 URL이 있는지 검사한다.  
3. 데이터베이스에 있다면 해당 단축 URL을 가져와서 클라이언트에게 반환한다.  
4. 데이터베이스에 없다면 유일한 ID를 생성한다. 이 ID는 데이터베이스의 기본 키로 사용된다.  
5. 62진법 변환을 적용, ID를 단축 URL로 만든다.  
6. ID, 단축 URL, 원래 URL로 새 데이터베이스 레코드를 만든 후, 단축 URL을 클라이언트에 전달한다.  
  
    
### URL 리디렉션 상세 설계  
로드밸런서의 동작 흐름은 다음과 같이 요약할 수 있다.  
1. 사용자가 단축 URL을 클릭한다.  
2. 로드밸런서가 해당 클릭으로 발생한 요청을 웹 서버에 전달한다.  
3. 단축 URL이 이미 캐시에 있는 경우에는 원래 URL을 바로 꺼내서 클라이언트에게 전달한다.  
4. 캐시에 해당 단축 URL이 없는 경우에는 데이터베이스에서 꺼낸다.  
5. 데이터베이스에서 꺼낸 URL을 캐시에 넣은 후 사용자에게 반환한다.  
  
  
  
## 4단계 마무리  
시간이 조금 남는다면 다음과 같은 것을 면접관과 이야기 할 수 있다.  
1. 처리율 제한 장치(rate limiter)  
지금까지 살펴본 시스템은 엄청난 양의 URL 단축 요청이 밀려들 경우 무력화될 수 있다.  
처리율 제한 장치를 두면 IP 주소를 비록한 필터링 규칙들을 이용해 걸러낼 수 있을 것이다.  
  
2. 웹 서버의 규모 확장  
본 설계에 포함된 웹 계층은 무상태 계층이므로, 웹 서버를 자유로이 증설하거나 삭제할 수 있다.  
  
3. 데이터베이스의 규모 확장  
데이터베이스를 다중화하거나 샤딩하여 규모 확장성을 달성할 수 있다.  
  
4. 데이터 분석 솔루션  
URL 단축기에 데이터 분석 솔루션을 통해 두면 어떤 링크를 얼마나 많은 사용자가 클릭했는지, 언제 주로 클릭했는지 등 중요한 정보를 알아낼 수 있다.  
  
5. 가용성, 데이터 일관성, 안정성  
대규모 시스템이 성공적으로 운영되기 위해서는 반드시 갖추어야 할 속성.  
  
  
  
# 9장 웹 크롤러 설계  
웹크롤러는 ``로봇`` 또는 ``스파이더``라고도 부른다.  
검색 엔진에서 널리 쓰는 기술로, 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아내는 것이 주된 목적.  
  
크롤러는 다양하게 이용된다.  
1. 검색 엔진 인덱싱: 크롤러는 웹 페이지를 모아 검색 엔진을 위한 로컬 인덱스를 만든다.  
2. 웹 아키이빙: 나중에 사용할 목적으로 장기보관하기 위해 웹에서 정보를 모으는 절차.  
3. 웹 마이닝: 웹 마이닝을 통해 인터넷에서 유용한 지식을 도출해 낼 수 있다.  
4. 웹 모니터링: 인터넷에서 저작권이나 상표권이 침해되는 사례를 모니터링.  
  
  
## 1단계 문제 이해 및 설계 범위 확정  
웹 크롤러의 기본 알고리즘  
1. URL 집합이 입력으로 주어지면, 해당 URL들이 가리키는 모든 웹 페이지를 다운로드한다.  
2. 다운받은 웹 페이지에서 URL들을 추출한다.  
3. 추출된 URL들을 다운로드할 URL 목록에 추가하고 위의 과정을 처음부터 반복한다.  
  
크롤러의 기능 요구사항을 명확히 하고, 만족 시켜야 할 속성  
1. 규모 확정성: 병행성을 활용.  
2. 안정성: 비정상적 입력이나 환경에 잘 대응해야 한다.  
3. 예절: 수집 대상 웹 사이트에 짧은 시간 동안 너무 많은 요청을 보내서는 안된다.  
4. 확장성: 새로운 형태의 콘텐츠를 지원하기가 쉬워야 한다.  
  
  
## 3단계 상세 설계  
### DFS VS BFS  
웹은 유향 그래프(directed graph)와 같다. 페이지는 노드이고, 하이퍼링크(URL)는 에지라고 보면 된다.  
크롤링 프로세스는 이 유향 그래프를 에지를 따라 탐색하는 과정이다.  
DFS는 그래프 크기가 클 경우 어느 정도로 깊숙이 가게 될지 가늠하기 어려워서 좋은 방법이 아닐 가능성이 높다.  
  
BFS 구현법에는 두 가지 문제점이 있다.  
1. 한 페이지에서 나오는 링크의 상당수는 같은 서버로 되돌아간다.  
이때 링크들을 병렬로 처리하게 된다면 서버는 수많은 요청으로 과부하에 걸리게 될 것이다.  
  
2. 표준적 알고리즘은 URL 간에 우선순위를 두지 않는다.  
하지만 모든 웹 페이지가 같은 수준의 품질, 같은 수준의 중요성을 갖지는 않는다.  
  
  
### 미수집 URL 저장소  
#### 미수집 URL 저장소를 위한 지속성 저장장치  
대부분의 URL은 디스크에 두지만 IO 비용을 줄이기 위해 메모리 버퍼에 큐를 둔다.  
버퍼에 있는 데이터는 주기적으로 디스크에 기록한다.  
  
  
### HTML 다운로더  
HTML 다운로더는 HTTP 프로토콜을 통해 웹 페이지를 내려 받는다.  
  
#### robots.txt  
로봇 제외 프로토콜이라고도 부르는 이 파일은 웹사이트가 크롤러와 소통하는 표준적 방법이다.  
이 파일에는 크롤러가 수집해도 되는 페이지 목록이 들어 있다.  
  
#### 성능 최적화  
HTML 다운로더에 사용할 수 있는 성능 최적화 기법들이 있다.  
1. 분산 크롤링  
크롤링 작업을 여러 서버에 분산하고, 각 서버는 여러 스레드를 돌려 다운로드 작업을 처리한다.  
  
2. 도메인 이름 변환 결과 캐시  
DNS 조회 결과로 얻어진 도메인 이름과 IP 주소 사이의 관계를 캐시에 보관해 놓고, 크론 잡 등을 돌려 주기적으로 갱신하도록 한다.  
  
3. 지역성  
크롤링 작업을 수행하는 서버를 지역별로 분산한다.  
  
4. 짧은 타임아웃  
대기 시간을 미리 정해준다.  
  
  
### 안정성 확보 전략  
최적화된 성능뿐 아니라 안정성도 다운로더 설계 시 중요하게 고려해야 할 부분이다.  
1. 안정성  
다운로더 서버들에 부하를 분산할 때 적용 가능한 기술로, 다운로더 서버를 쉽게 추가하고 삭제할 수 있다.  
  
2. 크롤링 상태 및 수집 데이터 저장  
장애가 발생한 경우에도 쉽게 복구할 수 있도록 크롤링 상태와 수집된 데이터를 지속적 저장장치에 기록해 둔다.  
  
3. 예외 처리: 예외가 발생해도 전체 시스템이 중단되는 일 없이 그 작업을 우아하게 이어나갈 수 있어야 한다.  
  
### 문제 있는 콘텐츠 감지 및 회피 전략  
1. 중복 컨텐츠: 해시나 체크섬을 사용하면 중복 컨텐츠를 보다 쉽게 탐지할 수 있다.  
2. 거미 덫: URL의 최대 길이를 제한하거나, URL 필터 목록에 걸어둔다.  
3. 데이터 노이즈: 가치 없는 콘첸츠는 가능하다면 제외한다.  
  
  
  
# 10장 알림 시스템 설계  
알림 시스템 기능을 갖춘 애플리케이션 프로그램은 최신 뉴스, 제품 업데이트, 이벤트, 선물 등 고객에게 중요할 만한 정보를 비동기적으로 제공한다.  
  
## 2단계 개략적 설계안 제시 및 동의 구하기  
### 알림 유형별 지원 방안  
#### ios 푸시 알림  
- 알림 제공자: 알림 요청을 만들어 애플 푸시 알림 서비스(APNS)로 보내는 주체.  
단말 토큰, 페이로드와 같은 데이터가 필요하다.  
- APNS: 애플이 제공하는 원격 서비스. 푸시 알림을 ios 장치로 보내는 역할을 담당.  
- ios 단말: 푸시 알림을 수신하는 사용자 단말  
  
#### 안드로이드 푸시 알림  
APNS 대신 FCM을 사용한다는 점만 다르고 비슷한 절차로 전송된다.  
  
#### SMS 메세지  
보통 트윌리오, 넥스모 같은 제3사업자의 서비스를 많이 이용한다.  
  
#### 이메일  
대부분의 회사는 고유 이메일 서버를 구축할 역량이 있으나, 많은 회사가 사용 이메일 서비스를 이용한다.  
유명한 서비스로 센드그리드, 메일침프가 있다.  
  
  
## 3단계 상세 설계  
### 안정성  
분산 환경에서 운영될 알림 시스템을 설계할 때는 안정성을 확보하기 위한 사항 몇 가지를 반드시 고려해야 한다.  
  
#### 데이터 손실 방지  
알림 시스템은 알림 데이터를 데이터베이스에 보관하고 재시도 메커니즘을 구현해야 한다.  
알림 로그 데이터베이스를 유지하는 것이 한가지 방법이다.  
  
  
### 개선된 설계안  
알림 설계안에 없던 많은 컴포넌트를 추가.  
1. 알림 서버에 인증과 전송률 제한 기능을 추가  
2. 전송 실패에 대응하기 위한 재시도 기능 추가.(전송에 실패한 알림은 다시 큐에 넣고 지정된 횟수만큼 재시도)  
3. 전송 템플릿을 사용하여 알림 생성 과정을 단순화하고 알림 내용의 일관성을 유지  
4. 모니링과 추적 시스템을 추가하여 시스템 상태를 확인하고, 추후 시스템을 개선하기 쉽도록 함.  
  
  
## 4단계 마무리  
1. 안정성: 메시지 전송 실패율을 낮추기 위해 안정적인 재시도 메커니즘을 도입.  
2. 보안: 인증된 클라이언트만이 알림을 보낼 수 있도록 appKey, appSecret 등의 메커니즘을 이용.  
3. 이벤트 추적 및 모니터링: 알림 전송의 각 단계마다 이벤트를 추적하고 모니터링할 수 있는 시스템을 통합.  
4. 사용자 설정: 사용자가 알림 수신 설정을 조정.  
5. 전송률 제한: 사용자에게 알림을 보내는 빈도를 제한.  
  
  
  
# 11장 뉴스 피드 시스템 설계  
뉴스 피드: 홈 페이지 중앙에 지속적으로 업데이트되는 스토리들.  
  
## 2단계 개략적 설계안 제시 및 동의 구하기  
### 1-1. 피드 발행  
사용자가 스토리를 포스팅하면 해당 데이터를 캐시와 데이터베이스에 기록한다.  
새 포스팅은 친구의 뉴스 피드에도 전송된다.  
  
### 1-2. 피드 발행 시스템의 개략적 형태  
- 포스팅 저장 서비스: 새 포스팅을 데이터베이스와 캐시에 저장한다.  
- 포스팅 전송 서비스: 새 포스팅을 친구의 뉴스 피드에 푸시한다. 뉴스 피드 데이터는 캐시에 보관하여 빠르게 읽어갈 수 있도록 한다.  
- 알림 서비스: 친구들에게 새 포스팅이 올라왔음을 알리거나, 푸시 알림을 보내는 역할을 담당한다.  
  
  
### 2-1. 뉴스 피드 생성  
지면 관계상 뉴스 피드는 모든 친구의 포스팅을 시간 흐름 역순으로 모아서 만든다고 가정.  
  
### 2-2. 뉴스 피드 시스템의 개략적 형태  
- 뉴스 피드 서비스: 캐시에서 뉴스 피드를 가져오는 서비스다.  
- 뉴스 피드 캐시: 뉴스 피드를 렌더링할 때 필요한 피드 ID를 보관한다.  
  
  
## 3단계 상세 설계  
#### 웹서버  
웹서버는 클라이언트와 통신할 뿐 아니라 인증이나 처리율 제한 등의 기능도 수행한다.  
올바른 인증 토큰을 Authorization 헤더에 넣고 API를 호출하는 사용자만 포스팅을 할 수 있어야 한다.  
또한 특정 기간 동안 한 사용자가 올릴 수 있는 포스팅의 수에 제한을 두어야 한다.  
  
#### 포스팅 전송(팬아웃) 서비스  
어떤 사용자의 새 포스팅을 그 사용자와 친구 관계에 있는 모든 사용자에게 전달하는 과정이다.  
쓰기 시점에 팬아웃 하는 모델, 읽기 시점에 팬아웃하는 모델이 있다.  
  
#### 1. 쓰기 시점에 팬아웃 하는 모델  
새로운 포스팅을 기록하는 시점에 뉴스 피드를 갱신  
장점  
1. 뉴스 피드가 실시간으로 생신되며 친구 목록에 있는 사용자에게 즉시 전송  
2. 새 포스팅이 기록되는 순간에 뉴스 피드가 이미 갱신되므로, 뉴스 피드를 읽는 데 드는 시간이 짧아진다.  
  
단점  
1. 친구가 많은 사용자의 경우 많은 시간이 소요될 수 있다.(핫키)  
2. 서비스를 자주 이용하지 않는 사용자의 피드까지 갱신해야 하므로 자원이 낭비된다.  
  
#### 2. 읽기 시점에 팬아웃하는 모델  
피드를 읽어야 하는 시점에 뉴스 피드를 갱신  
장점  
1. 로그인하기 까지 어떤 컴퓨팅 자원도 소모하지 않는다.  
2. 데이터를 친구 각각에 푸시하는 작업이 필요 없다.(핫키 문제가 생기지 않는다.)  
  
단점  
1. 뉴스 피드를 읽는 데 많은 시간이 소요될 수 있다.  
  
  
#### 이 두 가지 방법을 결합하여 장점은 취하고 단점은 버리는 전략  
1. 뉴스 피드를 빠르게 가져올 수 있도록 하는 것은 중요하므로, 대부분의 사용자에 대해서 푸시 모델을 사용.  
2. 친구나 팔로어가 많은 사용자의 경우에는 팔로어로 하여금 필요할 때 가져가도록 하는 풀 모델을 사용.(시스템 과부하 방지)  
3. 안정 해시(consistent hashing)를 통해 요청과 데이터를 보다 고르게 분산하여 핫키 문제를 줄인다.  
  
  
  
# 12장 채팅 시스템 설계  
## 1단계 문제 이해 및 설계 범위 확정  
1. 응답지연이 낮은 일대일 채팅 기능  
2. 최대 100명까지 참여할 수 있는 그룹 채팅 기능  
3. 사용자의 접속상태 표시 기능  
4. 다양한 단말 지원. 하나의 계정으로 여러 단말에 동시 접속 지원  
5. 푸시 알림  
6. 5천만 DAU(일별 능동 사용자수: Daily Active User)를 처리할 수 있어야 함  
  
  
## 2단계 개략적 설계안 제시 및 동의 구하기  
채팅서비스는 아래 기능을 제공해야 한다.  
1. 클라이언트들로부터 메시지 수신  
2. 메시지 수신자 결정 및 전달  
3. 수신자가 접속 상태가 아닌 경우에는 접속할 때까지 해당 메시지 보관  
  
HTTP는 클라이언트가 연결을 만드는 프로토콜이며, 서버에서 클라이언트로 임의 시점에 메시지를 보내는 데는 쉽게 쓰일 수 없다.  
서버가 연결을 만드는 것처럼 동작할 수 있도록 하기 위해 많은 기법이 제안되어 왔는데, ``폴링, 롱 폴링, 웹소켓`` 등이 그런 기술이다.  
  
#### 1. 폴링  
클라이언트가 주기적으로 서버에게 새 메시지가 있느냐고 물어보는 방법이다.  
폴링 비용은 폴링을 자주하면 할수록 올라간다.  
  
#### 2. 롱 폴링  
클라이언트는 새 메시지가 반환되거나 타임아웃 될 때까지 연결을 유지한다.  
클라이언트는 새 메시지를 받으면 기존 연결을 종료하고 서버에 새로운 요청을 보내어 모든 절차를 다시 시작한다.  
그러나 메시지를 보내는 클라이언트와 수신하는 클라이언트가 같은 채팅 서버에 접속하게 되지 않을 수도 있다.  
서버 입장에서는 클라이언트가 연결을 해제했는지 알 수 없고, 메시지를 많이 받지 않는 클라이언트도 타임아웃이 일어날 때마다 접속해서 비효율적이다.  
  
#### 3. 웹소켓  
웹소켓은 일반적으로 방화벽이 있는 환경에서도 잘 동작하며, 양방향 메시지 전송까지 가능하다.  
메시지를 보낼 때나 받을 때 동일한 프로토콜을 사용할 수 있으므로 설계뿐 아니라 구현도 단순하고 직관적이다.  
유의할 것은 연결은 항구적으로 유지되어야 하기 때문에 서버 측에서 연결 관리를 효율적으로 해야 한다.  
  
  
### 개략적 설계안  
#### 무상태 서비스  
이 설계안에서 무상태 서비스는 로그인, 회원가입, 사용자 프로파일 표시 등을 처리하는 전통적인 요청/응답 서비스다.  
무상태 서비스가 제공하는 기능은 많은 웹사이트와 앱이 보편적으로 제공하는 기능이다.  
  
#### 상태유지 서비스  
본 설계안에서 유일하게 상태 유지가 필요한 서비스는 채팅 서비스다.  
  
#### 제3자 서비스 연동  
채팅 앱에서 가장 중요한 제3자 서비스는 푸시 알림이다.  
새 메시지를 받았다면 앱이 실행 중이지 않더라도 알림은 받아야 한다.  
  
  
## 3단계 상세설계  
### 서비스 탐색  
서비스 탐색 기능의 주된 역할은 클라이언트에게 가장 적합한 채팅 서버를 추천하는 것이다.  
이때 사용되는 기준은 클라이언트의 위치, 서버의 용량 등이 있다.  
서비스 탐색 기능을 구현하는 데 널리 쓰이는 오픈소스 솔루션으로는 ``아파치 주키퍼``같은 것이 있다.  
사용 가능한 모든 채팅 서버를 여기 등록시켜 두고, 클라이언트가 접속을 시도하면 사전에 정한 기준에 따라 최적의 채팅 서버를 골라 주면 된다.  
  
### 메시지 전달 흐름  
### 사용자 접속 상태를 표시하는 방법  
접속상태 서버를 통해 사용자의 상태를 괸리한다.  
(접속상태 서버는 클라이언트와 웹소켓으로 통신하는 실시간 서비스의 일부)  
  
#### 접속 장애  
짧은 시간 동안 인터넷 연결이 끊어졌다 복구되는 일은 흔하므로, 박동 검사를 통해 이 문제를 해결할 수 있다.  
온라인 상태의 클라이언트로 하여금 주기적으로 박동 이벤트를 접속상태 서버로 보내도록 하고,  
마지막 이벤트를 받은 지 x초 이내에 또 다른 박동 이벤트 메시지를 받으면, 해당 사용자의 접속 상태를 계속 온라인으로 유지하는 것이다.  
(그렇지 않을 경우에만 오프라인으로 바꾸는 것이다.)  
  
  
끝  